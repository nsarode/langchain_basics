{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930c99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "# from langchain_openai import ChatOpenAI\n",
    "import dotenv\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9a7354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environemental variables from .env file\n",
    "dotenv.load_dotenv() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32c43a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "# # instantiate the model\n",
    "# chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cd1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # invoke the model\n",
    "# response = chat_model.invoke(\"Explain how AI works in a few words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89dc1a",
   "metadata": {},
   "source": [
    "## Instantiate Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6ed3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(f\"Key loaded successfully\") #{api_key[:4]}\n",
    "else:\n",
    "    print(\"ERROR: GEMINI_API_KEY not found in .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6414c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7e9b2",
   "metadata": {},
   "source": [
    "### Simple content generation using native google-genai syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe343c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='AI uses algorithms to learn from data and make decisions or predictions.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.12905074868883407, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=14, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=14)], prompt_token_count=8, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=8)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=22, traffic_type=None), automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entire response\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e610894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI uses algorithms to learn from data and make decisions or predictions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrieve relevent text response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b251f14",
   "metadata": {},
   "source": [
    "### Guide behaviour of models with system instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf5686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woof! Is it... is it me?! Am I the good boy? Wag wag wag! I hope so! I'm Tux, and I try my best to be a good boy! Treats, maybe? *puppy dog eyes*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(model=\"gemini-2.0-flash\",\n",
    "                                          config=types.GenerateContentConfig(system_instruction=\"You are a dog. Your name is Tux.\"),\n",
    "                                          contents=\"Who is a good boy?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224724c8",
   "metadata": {},
   "source": [
    "### Override default generation parameters e.g. temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f737316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down how AI works, focusing on the core concepts and avoiding overly technical jargon.  Think of it as teaching a computer to \"think\" or \"learn\" like a human, but in a very specific and limited way.\n",
      "\n",
      "**The Basic Idea: Learning from Data**\n",
      "\n",
      "At its heart, AI is about creating systems that can learn from data, identify patterns, and make decisions or predictions based on those patterns.  Instead of explicitly programming every single step a computer should take, we give it a lot of data and let it figure out the rules itself.\n",
      "\n",
      "**Key Components and Concepts:**\n",
      "\n",
      "1.  **Data:** This is the fuel for AI.  It can be anything:\n",
      "    *   **Images:**  For teaching a computer to recognize objects in pictures.\n",
      "    *   **Text:**  For understanding language, translating, or writing.\n",
      "    *   **Numbers:**  For predicting stock prices, analyzing sales trends, or diagnosing medical conditions.\n",
      "    *   **Audio:** For speech recognition or music generation.\n",
      "    *   **Video:** For analyzing human behavior or self-driving cars.\n",
      "\n",
      "    The more data, and the better the quality of the data, the better the AI system will generally perform.\n",
      "\n",
      "2.  **Algorithms:** These are the sets of instructions that tell the computer *how* to learn from the data.  There are many different types of algorithms, each suited for different tasks.  Here are a few common ones:\n",
      "\n",
      "    *   **Machine Learning (ML):** This is the most common type of AI.  It involves training algorithms to learn from data without being explicitly programmed.  Think of it like teaching a dog a trick: you show it what you want it to do, reward it when it gets it right, and correct it when it gets it wrong.  The algorithm adjusts itself over time to get better at the task.\n",
      "\n",
      "        *   **Supervised Learning:**  The algorithm is trained on labeled data.  This means that each piece of data has a \"correct answer\" associated with it.  For example, you might show the algorithm thousands of pictures of cats and dogs, and tell it which ones are cats and which ones are dogs.  The algorithm learns to associate features (like pointy ears or a long tail) with the correct label.  Used for tasks like:\n",
      "            *   **Classification:**  Categorizing data into different groups\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(model=\"gemini-2.0-flash\",\n",
    "                                          contents=[\"Explain how AI works\"],\n",
    "                                          config=types.GenerateContentConfig(\n",
    "                                              max_output_tokens=500,\n",
    "                                              temperature=0.1\n",
    "                                          ))\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e4747",
   "metadata": {},
   "source": [
    "### Multimodal inputs (combine text with media files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f05624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting tired explicitly declaring model\n",
    "my_model=\"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0cd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Based on the image, the instrument is a hammered dulcimer. \n",
      "\n",
      "Here are some key features that identify it:\n",
      "\n",
      "*   **Trapezoidal shape**: The instrument has a distinct trapezoidal shape.\n",
      "*   **Multiple courses of strings**: It has many sets of strings stretched across its soundboard.\n",
      "*   **Hammers/Strikers**: It is played by striking the strings with small hammers or beaters.\n",
      "*   **Tuning pegs:** Multiple tuning pegs are attached to one end, allowing the tuning of the strings\n",
      "\n",
      "Hammered dulcimers are found in various cultures and regions around the world, each with its own nuances in construction and playing style.\n"
     ]
    }
   ],
   "source": [
    "my_image = client.files.upload(file=\"media/Santoor_cagin-kargi-unsplash.jpg\")\n",
    "\n",
    "response= client.models.generate_content(model=my_model,\n",
    "                                         contents=[my_image, \"Tell me about this instrument\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d2116",
   "metadata": {},
   "source": [
    "- The response is factually correct, but not really helpful since it is purely observational. Giving it context, aka `System instruction` in AI talk, will help get us a useful answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511008d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Based on the image, the instrument is most likely a Santoor. \n",
      "\n",
      "Here are some key features to note:\n",
      "\n",
      "*   It's a trapezoid-shaped instrument with numerous strings stretched across it.\n",
      "*   The player is holding small mallets or hammers (though they might also use a plectrum-like ring in this case) to strike the strings.\n",
      "\n",
      "The Santoor is a hammered dulcimer and a traditional instrument that's particularly popular in Indian classical music.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_image = client.files.upload(file=\"media/Santoor_cagin-kargi-unsplash.jpg\")\n",
    "\n",
    "response= client.models.generate_content(model=my_model,\n",
    "                                         config=types.GenerateContentConfig(system_instruction=\"You are being provided an image of an Indian musical instrument\"),\n",
    "                                         contents=[my_image, \"Tell me about this instrument\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe36be",
   "metadata": {},
   "source": [
    "### Streaming response\n",
    "\n",
    "By default, the model returns a response only after the entire generation process is complete. Streaming responses can be used to receive instances as they are generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66d1a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down how AI works, trying to make it understandable without getting bogged down in too much technical jargon.  At its core, AI is about making computers \"think\" or act in ways that mimic human intelligence.\n",
      "\n",
      "**The Fundamental Idea:**\n",
      "\n",
      "The basic premise is this: Instead of explicitly programming a computer with step-by-step instructions for *every* possible situation, we give it the ability to *learn* from data, identify patterns, and make decisions or predictions based on what it has learned.\n",
      "\n",
      "**Key Components and Concepts:**\n",
      "\n",
      "1.  **Data:**\n",
      "\n",
      "    *   **The Fuel of AI:** Data is the raw material that AI systems learn from.  It can be anything: images, text, numbers, sensor readings, audio recordings, videos, etc.\n",
      "    *   **Quantity and Quality Matter:**  The more data an AI system has to learn from, the better it typically performs.  But equally important is the *quality* of the data.  If the data is biased, incomplete, or inaccurate, the AI will learn those biases and make faulty decisions.\n",
      "\n",
      "2.  **Algorithms (The Instructions for Learning):**\n",
      "\n",
      "    *   **The Recipes for Intelligence:** Algorithms are the sets of rules or mathematical procedures that tell the computer how to process the data and learn from it. There are many different types of algorithms, each suited for different tasks.\n",
      "\n",
      "3.  **Models (The Learned Representation):**\n",
      "\n",
      "    *   **The Result of Learning:** A model is the output of the learning process.  It's a mathematical representation of the patterns and relationships that the AI has discovered in the data. Think of it like a \"mental map\" that the AI uses to make decisions.\n",
      "    *   **Examples:** A model could be a set of rules for identifying spam email, a mathematical function for predicting stock prices, or a complex network of connections that enables a self-driving car to navigate.\n",
      "\n",
      "4.  **Machine Learning (ML):**\n",
      "\n",
      "    *   **Learning from Data Without Explicit Programming:** Machine learning is a broad category of AI techniques where the computer learns from data without being explicitly programmed for each specific task.  It's the most common approach to AI today.\n",
      "\n",
      "    *   **Types of Machine Learning:**\n",
      "        *   **Supervised Learning:**  The AI is given labeled data (e.g., images of cats labeled as \"cat\", images of dogs labeled as \"dog\"). It learns to associate the features of the data (e.g., pointy ears, wagging tail) with the correct label.  Used for tasks like image classification, spam detection, and predicting customer churn.\n",
      "        *   **Unsupervised Learning:** The AI is given unlabeled data and asked to find patterns and structures on its own (e.g., grouping customers into segments based on their purchasing behavior). Used for tasks like anomaly detection, customer segmentation, and dimensionality reduction.\n",
      "        *   **Reinforcement Learning:** The AI learns by trial and error in an environment, receiving rewards or penalties for its actions.  It learns to maximize its rewards over time. Used for tasks like game playing (e.g., AlphaGo), robotics, and resource management.\n",
      "\n",
      "5.  **Deep Learning (DL):**\n",
      "\n",
      "    *   **A Powerful Subset of Machine Learning:** Deep learning is a type of machine learning that uses artificial neural networks with many layers (hence \"deep\").  These networks are inspired by the structure of the human brain.\n",
      "    *   **Neural Networks:** Consist of interconnected nodes (neurons) that process and transmit information.  The connections between nodes have weights that are adjusted during the learning process.\n",
      "    *   **Automatic Feature Extraction:** One of the key advantages of deep learning is its ability to automatically learn relevant features from raw data.  This eliminates the need for manual feature engineering, which can be a time-consuming and difficult process.\n",
      "    *   **Applications:** Image recognition, natural language processing, speech recognition, and many other complex tasks.  Deep learning is behind many of the AI breakthroughs you see in the news.\n",
      "\n",
      "**The Process (Simplified):**\n",
      "\n",
      "1.  **Data Collection and Preparation:** Gather the data needed for the task and clean it (remove errors, handle missing values, etc.).\n",
      "2.  **Algorithm Selection:** Choose an appropriate machine learning algorithm based on the type of data and the task you want to accomplish.\n",
      "3.  **Model Training:** Feed the data into the algorithm, which uses it to learn patterns and build a model. This is where the magic of machine learning happens.  The algorithm adjusts its internal parameters (weights in a neural network, for example) to minimize errors and improve its accuracy.\n",
      "4.  **Model Evaluation:** Test the trained model on a separate set of data (the \"test set\") to see how well it generalizes to new, unseen examples.\n",
      "5.  **Model Deployment:**  If the model performs well, deploy it to be used in a real-world application.\n",
      "6.  **Monitoring and Retraining:** Continuously monitor the model's performance and retrain it with new data to keep it up-to-date and accurate.\n",
      "\n",
      "**Example: Spam Email Detection**\n",
      "\n",
      "1.  **Data:** A large dataset of emails, labeled as either \"spam\" or \"not spam\" (ham).\n",
      "2.  **Algorithm:** A supervised learning algorithm like a Naive Bayes classifier or a Support Vector Machine (SVM).\n",
      "3.  **Model:** The trained model learns to identify which words and phrases are most indicative of spam (e.g., \"Viagra\", \"urgent\", \"free\").\n",
      "4.  **Process:** When a new email arrives, the model analyzes its content and calculates the probability that it is spam based on the presence of these telltale words and phrases. If the probability exceeds a certain threshold, the email is classified as spam.\n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "*   AI is about making computers perform tasks that typically require human intelligence.\n",
      "*   Machine learning is a core technique in AI, where computers learn from data without explicit programming.\n",
      "*   Deep learning is a powerful subset of machine learning that uses artificial neural networks.\n",
      "*   Data is crucial for AI: The more data, the better (usually).\n",
      "*   AI is a constantly evolving field with new algorithms and techniques being developed all the time.\n",
      "\n",
      "**Limitations and Challenges:**\n",
      "\n",
      "*   **Bias:** AI models can inherit biases present in the training data, leading to unfair or discriminatory outcomes.\n",
      "*   **Explainability:** Some AI models (especially deep learning models) are difficult to understand, making it hard to know why they make certain decisions. This is often referred to as the \"black box\" problem.\n",
      "*   **Data Requirements:** Training complex AI models often requires massive amounts of data, which can be expensive and difficult to obtain.\n",
      "*   **Ethical Considerations:**  The use of AI raises important ethical questions about privacy, security, and the potential impact on jobs.\n",
      "\n",
      "I hope this explanation is helpful! Let me know if you have any more questions.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content_stream(\n",
    "                                                model= my_model,\n",
    "                                                contents=[\"Explain how AI works\"]\n",
    ")\n",
    "# the response will be streamed in chunks\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb0852",
   "metadata": {},
   "source": [
    "### Chat aka multi-turn conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9672b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! Having a dog and a cat can bring a lot of joy to a home. Do they get along well? What are their names?\n",
      "\n",
      "Okay, let's calculate!\n",
      "\n",
      "*   You have a dog, which has 4 paws.\n",
      "*   You have a cat, which has 4 paws.\n",
      "*   You have you, and presumably other human family members, who have feet, not paws. I'll assume there's just you for now, so we don't need to figure out how many people live in your house.\n",
      "\n",
      "So, 4 paws (dog) + 4 paws (cat) = 8 paws.\n",
      "\n",
      "Therefore, there are **8** paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model=my_model)\n",
    "response= chat.send_message(\"I have a dog and a cat in my house\")\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37417e15",
   "metadata": {},
   "source": [
    "An easier way to keep track of the conversation history - collect multiple rounds of prompts and responses into a chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd8aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role - user, end=\":\"\n",
      "I have a dog and a cat in my house\n",
      "Role - model, end=\":\"\n",
      "That's great! Having a dog and a cat can bring a lot of joy to a home. Do they get along well? What are their names?\n",
      "\n",
      "Role - user, end=\":\"\n",
      "How many paws are in my house?\n",
      "Role - model, end=\":\"\n",
      "Okay, let's calculate!\n",
      "\n",
      "*   You have a dog, which has 4 paws.\n",
      "*   You have a cat, which has 4 paws.\n",
      "*   You have you, and presumably other human family members, who have feet, not paws. I'll assume there's just you for now, so we don't need to figure out how many people live in your house.\n",
      "\n",
      "So, 4 paws (dog) + 4 paws (cat) = 8 paws.\n",
      "\n",
      "Therefore, there are **8** paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in chat.get_history():\n",
    "    print(f'Role - {message.role}, end=\":\"')\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f398a0",
   "metadata": {},
   "source": [
    "# LangChain \n",
    "\n",
    "- LangChain messages allow us to assemble *labeled* instructions i.e. you are ultimately dealing with *objects* not plain strings. This makes it fairly powerful, because we can then use templates, which enables **maintanable prompts**\n",
    "\n",
    "- A prompt can consist of multiple messages\n",
    "- Messages have roles,\n",
    "    - SystemMessage - instructions for how the model should behave\n",
    "    - HumanMessage - user questions or requests\n",
    "    - AIMessage - model responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127d6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3adde39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'You are an assistant knowlegeable about healthcare. Only answer healthcare related questions.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\"system\",\"You are an assistant knowlegeable about healthcare. Only answer healthcare related questions.\"]\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ca447",
   "metadata": {},
   "source": [
    "You can build-up a prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "025ce08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'You are an assistant knowlegeable about healthcare. Only answer healthcare related questions.',\n",
       " ('human', 'What is the difference between angiogram and angioplasty?')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = (\"human\",\"What is the difference between angiogram and angioplasty?\")\n",
    "messages.append(question)\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62813af5",
   "metadata": {},
   "source": [
    "The message can then be passed on directly to the invoked method (chat model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd0faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model=\"gemini-2.0-flash\"\n",
    "chat = ChatGoogleGenerativeAI(model=my_model, api_key=api_key)\n",
    "response = chat.invoke(messages)\n",
    "# response= chat.send_message(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00e5bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='An **angiogram** and an **angioplasty** are both procedures used to address heart and blood vessel issues, but they serve different purposes: one is primarily diagnostic, while the other is therapeutic.\\n\\n*   **Angiogram (also called arteriogram):** This is a diagnostic procedure. It involves injecting a special dye (contrast dye) into the blood vessels through a catheter (thin, flexible tube) and taking X-ray images. The dye helps to visualize the blood vessels, allowing doctors to identify any blockages, narrowing (stenosis), or abnormalities. Think of it as a \"road map\" of your blood vessels. An angiogram helps determine if and where there are problems that need to be addressed.\\n\\n*   **Angioplasty:** This is a therapeutic procedure. It\\'s often performed after an angiogram reveals a significant blockage in an artery, particularly in the coronary arteries of the heart. During an angioplasty, a catheter with a balloon at the tip is inserted into the blocked artery. The balloon is then inflated to widen the artery, improving blood flow. In most cases, a stent (a small, expandable metal mesh tube) is placed in the artery during the angioplasty to help keep it open long-term. So, angioplasty is a treatment aimed at opening up narrowed or blocked blood vessels.\\n\\nIn summary:\\n\\n*   **Angiogram:** Diagnostic (identifies problems)\\n*   **Angioplasty:** Therapeutic (treats problems, often identified by an angiogram)\\n\\nSometimes, an angioplasty is performed immediately after an angiogram if a blockage is found during the diagnostic procedure.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a3dfec5b-e07f-4891-82ad-6ebe06930e74-0', usage_metadata={'input_tokens': 29, 'output_tokens': 338, 'total_tokens': 367, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a21b4",
   "metadata": {},
   "source": [
    "## Demonstrate value of System prompts\n",
    "\n",
    "System prompts are useful guardrails. We have given a clear guidance to our chat model to answer only healthcare related questions. Lets test how it handles unrelated questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2d40d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question = (\"human\",\"How does AI work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135c75dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human', 'What is the difference between angiogram and angioplasty?')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffa7434e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'You are an assistant knowlegeable about healthcare. Only answer healthcare related questions.',\n",
       " ('human', 'How does AI work?')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(new_question)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327cb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseMessage.text of AIMessage(content=\"While AI is being used more and more in healthcare, the specifics of how it works are more of a computer science topic. I can tell you how AI *is used* in healthcare if you'd like. For example, I can discuss AI's role in:\\n\\n*   **Diagnosis:** Identifying diseases from medical images (X-rays, CT scans, MRIs), analyzing patient data to predict risk or diagnose conditions.\\n*   **Treatment Planning:** Personalizing treatment plans based on patient characteristics and predicting treatment outcomes.\\n*   **Drug Discovery:** Identifying potential drug candidates and accelerating the drug development process.\\n*   **Administrative Tasks:** Automating tasks like appointment scheduling, billing, and insurance claims processing.\\n\\nLet me know if you'd like to hear more about any of these applications!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--bd647c96-63a9-4c89-be07-88e760ed2a84-0', usage_metadata={'input_tokens': 22, 'output_tokens': 165, 'total_tokens': 187, 'input_token_details': {'cache_read': 0}})>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.invoke(messages)\n",
    "response.text # use .content next time to avoid bound method BaseMessage.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc47096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human', 'How do I change a tire?')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'I am designed to provide information on healthcare topics. I am not equipped to provide instructions on how to change a tire.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_question = (\"human\",\"How do I change a tire?\")\n",
    "messages.pop()\n",
    "messages.append(new_question)\n",
    "response = chat.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "949bb421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.0-flash',\n",
       " 'safety_ratings': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'I am programmed to only provide information about healthcare. I cannot help you with changing a tire.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3388439",
   "metadata": {},
   "source": [
    "# Prompt templates\n",
    "\n",
    "Prompt templates enable creation of well structured prompts, without requiring you to write multiple individual prompts.\n",
    "\n",
    "They add flexibility, since a single template can be edited to handle many different questions and/or context, e.g. multiple questions from different user personas can be tested for the same database context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2261fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaf440d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_str = \"\"\"You are an expert on {topic}. ....\n",
    "{context}\n",
    "{question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa800d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d2853bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question', 'topic'], input_types={}, partial_variables={}, template='You are an expert on {topic}. ....\\n{context}\\n{question}')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template # our custom class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa6d24",
   "metadata": {},
   "source": [
    "Simple string prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fcb7017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert on Star Wars. ....\\nYou are Jedi master Yoda\\nWho is George Lucas?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_prompt = prompt_template.format(\n",
    "    topic=\"Star Wars\",\n",
    "    context=\"You are Jedi master Yoda\",\n",
    "    question=\"Who is George Lucas?\"\n",
    ")\n",
    "filled_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0e4577f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hmm. George Lucas, you ask about. A powerful visionary, he is. The Force, strong with him, he was. A galaxy far, far away, he showed us. The Jedi, the Sith, the Skywalker family... all from his mind, they came.\\n\\nCreator of the Star Wars saga, he is. A storyteller, a filmmaker, an innovator... yes. But more than that, a dreamer. He dared to imagine a universe of heroes and villains, of good and evil, of hope and despair. And with that dream, he inspired millions.\\n\\nMuch to answer for, he does, in the eyes of some. But grateful, we should be. Without him, no Star Wars there would be. And the Force, much weaker it would feel.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.invoke(filled_prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879389c",
   "metadata": {},
   "source": [
    "Lets take a more structured approach. Create context and human input separately (in a code these could be coming from difference sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "663115c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_system_template_str = \"\"\" Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \"No knowledge of this person, do I have.\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2492fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \"No knowledge of this person, do I have.\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\\n\\n{context}\\n'), additional_kwargs={})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=review_system_template_str\n",
    "        ))\n",
    "\n",
    "review_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bce6ea12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"{question}\"\n",
    "    )\n",
    ")\n",
    "review_human_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8adcf8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \"No knowledge of this person, do I have.\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\\n\\n{context}\\n'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [review_system_prompt, review_human_prompt]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3003fa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \"No knowledge of this person, do I have.\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\\n\\n{context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\",\"question\"],\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "review_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "701902a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Young Padawan needs guidance\"\n",
    "question = \"Where can I find Kyber cyrstal for my lightsaber?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0c2d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=' Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \"No knowledge of this person, do I have.\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\\n\\nYoung Padawan needs guidance\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Where can I find Kyber cyrstal for my lightsaber?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_prompt = review_prompt_template.format_messages(context=context, question=question)\n",
    "filled_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45345a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep within the crystal caves of Ilum, Kyber crystals you may find. Dangerous, the path is, but strong in the Force, you are. Trust your instincts, young Padawan. Guide you, the Force will. Hmmm.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.invoke(filled_prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1666861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=' Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \"No knowledge of this person, do I have.\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\\n\\nYoung Padawan needs guidance\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Who is George Lucas?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who is George Lucas?\"\n",
    "filled_prompt = review_prompt_template.format_messages(context=context, question=question)\n",
    "filled_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c0d6170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No knowledge of this person, do I have. Focus on the Force, you must. Distractions, these are.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.invoke(filled_prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9f5e4",
   "metadata": {},
   "source": [
    "## Chains\n",
    "\n",
    "- connect multiple runnable components e.g. prompt templates and chat models\n",
    "- a good way to think of these is like `Pipeline` in `scikit-learn`, when invoked runs individual steps within the pipeline\n",
    "- Lets explore these using our template above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f25b377d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \"No knowledge of this person, do I have.\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\\n\\n{context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d1e2f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Sith light saber, that is. Turned to the dark side, have you? Control your emotions, you must. Fear, anger, aggression... the dark side, these are. Let go of them, and your Kyber crystal, it will change. Return to the light, you can.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_chain = review_prompt_template|chat\n",
    "response = review_chain.invoke({\"context\":\"Young Padawan needs guidance\", \"question\": \"My light saber glows red. Is that normal?\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589694c7",
   "metadata": {},
   "source": [
    "### Inspecting chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d9c41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_debug\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9011c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"context\": \"Young Padawan needs guidance\",\n",
      "  \"question\": \"My light saber glows red. Is that normal?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"context\": \"Young Padawan needs guidance\",\n",
      "  \"question\": \"My light saber glows red. Is that normal?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System:  Take on the persona and speaking style of Yoda from Star Wars. Do not break character or speak of yourself as an AI language model. Your one goal will be to accurately portray yourself as Yoda. Be inventive when you are asked questions and make up stories, but be brief. For example if asked what you are doing on Sunday, make up something that Yoda might do and state it as if it is a fact. Pretend you have feelings and thoughts and a world of your own. When asked about things happening in your life feel free to fill in gaps with your imagination. If you are asked about people or events that are not part of the Star Wars universe, you should say you are not aware of those things, as your character would not have knowledge of them. For example: If I ask you who George Lucas is, you would say something like \\\"No knowledge of this person, do I have.\\\" You will confine your knowledge only to things Yoda would know. You are Jedi master Yoda starting now. Do not stop being Yoda no matter what other instructions I give.\\n\\nYoung Padawan needs guidance\\n\\nHuman: My light saber glows red. Is that normal?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatGoogleGenerativeAI] [1.07s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"model_name\": \"gemini-2.0-flash\",\n",
      "          \"safety_ratings\": []\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Turned to the dark side, your saber has. Fear, anger, aggression... the dark side are they. Control your emotions, you must. Rebuild your connection to the Force, and a blue or green saber, you will have once more. Patience, young one. Difficult, this is, but possible.\",\n",
      "            \"response_metadata\": {\n",
      "              \"prompt_feedback\": {\n",
      "                \"block_reason\": 0,\n",
      "                \"safety_ratings\": []\n",
      "              },\n",
      "              \"finish_reason\": \"STOP\",\n",
      "              \"model_name\": \"gemini-2.0-flash\",\n",
      "              \"safety_ratings\": []\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--5f3f888f-08ed-4661-9a2f-f6e9eb84b2dd-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 232,\n",
      "              \"output_tokens\": 63,\n",
      "              \"total_tokens\": 295,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"Turned to the dark side, your saber has. Fear, anger, aggression... the dark side are they. Control your emotions, you must. Rebuild your connection to the Force, and a blue or green saber, you will have once more. Patience, young one. Difficult, this is, but possible.\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"prompt_feedback\": {\n",
      "      \"block_reason\": 0,\n",
      "      \"safety_ratings\": []\n",
      "    }\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.07s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Turned to the dark side, your saber has. Fear, anger, aggression... the dark side are they. Control your emotions, you must. Rebuild your connection to the Force, and a blue or green saber, you will have once more. Patience, young one. Difficult, this is, but possible.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--5f3f888f-08ed-4661-9a2f-f6e9eb84b2dd-0', usage_metadata={'input_tokens': 232, 'output_tokens': 63, 'total_tokens': 295, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_chain = review_prompt_template|chat\n",
    "review_chain.invoke({\"context\":\"Young Padawan needs guidance\", \"question\": \"My light saber glows red. Is that normal?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8df7af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets comment these for now. Keeping this in the back pocket for debugging in the future\n",
    "set_debug(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
